#summary Wiki-fied version of the s3backer man page

Apologies for the funky syntax highlighting. There doesn't seem to be a way to disable the wiki syntax...

{{{
S3BACKER(1)                                         BSD General Commands Manual                                         S3BACKER(1)

NAME
     s3backer - FUSE-based single file backing store via Amazon S3

SYNOPSIS
     s3backer [options] bucket /mount/point

DESCRIPTION
     s3backer is a filesystem that contains a single file backed by the Amazon Simple Storage Service (Amazon S3).  As a filesys-
     tem, it is quite small and simple: it provides a single normal file having a fixed size.  The file is divided up into blocks,
     and the content of each block is stored in a unique Amazon S3 object.  In other words, what s3backer provides is really more
     like an S3-backed virtual hard disk device, rather than a filesystem.

     In typical usage, a `normal' filesystem is mounted on top of the file exported by the s3backer filesystem using a loopback
     mount.

     This arrangement has several benefits compared to more complete S3 filesystem implementations:

     o   By not attempting to implement a complete filesystem, which is a complex undertaking and difficult to get right, s3backer
         can stay very lightweight and simple. Only three HTTP operations are used: GET, PUT, and DELETE.  All of the experience
         and knowledge about how to properly implement filesystems that already exists can be reused.

     o   By utilizing existing filesystems, you get full UNIX filesystem semantics.  Subtle bugs or missing functionality relating
         to hard links, extended attributes, POSIX locking, etc. are avoided.

     o   The gap between normal filesystem semantics and Amazon S3 ``eventual consistency'' is more easily and simply solved when
         one can interpret S3 objects as simple device blocks rather than filesystem objects (see below).

     o   When storing your data on Amazon S3 servers, which are not under your control, the ability to encrypt data becomes a crit-
         ical issue.  s3backer provides this automatically because encryption support is already included in the Linux loopback
         mechanism.

     o   Since S3 data is accessed over the network, local caching is also very important for performance reasons.  Since s3backer
         presents the equivalent of a virtual hard disk to the kernel, all of the filesystem caching can be done where it should
         be: in the kernel, via the kernel's page cache.  s3backer itself does not cache any file data, nor does it need to.

   Consistency Guarantees
     Amazon S3 makes relatively weak guarantees relating to the timing and consistency of reads vs. writes (collectively known as
     ``eventual consistency'').  s3backer includes logic and configuration parameters to work around these limitations, allowing
     the user to guarantee consistency to whatever level desired, up to and including 100% detection and avoidance of incorrect
     data.  These are:

     1.  Regarding PUT/DELETE operations on the same block: avoidance of overlapping operations plus a configurable minimum delay
         between consecutive operations. This ensures S3 doesn't receive these operations out of order.

     2.  An internal MD5 checksum cache, which enables s3backer to automatically detect and reject `stale' information returned by
         GET operations.

     This logic is configured by the following command line options: --cacheSize, --cacheTime, --minWriteDelay,
     --initialRetryPause, and --maxRetryPause, all of which have default values.

   Zeroed Block Optimization
     As a simple optimization, s3backer does not store blocks containing all zeroes; instead, they are simply deleted.  Conversely,
     reads of non-existent blocks will contain all zeroes.

     As a result, no special initialization is necessary when creating a new filesystem.

   File and Block Size Auto-Detection
     As a convenience, whenever the first block of the backed file is written, s3backer includes as meta-data (in the ``x-amz-meta-
     s3backer-filesize'' header) the total size of the file.  Along with the size of the block itself, this value can be checked
     and/or auto-detected later when the filesystem is remounted, eliminating the need for the --blockSize or --size flags to be
     explicitly provided and avoiding accidental mis-interpretation of an existing filesystem (see below).

   Read-Only Access
     An Amazon S3 account is not required in order to use s3backer.  Of course a filesystem must already exist and have S3 objects
     with ACL's configured for public read access (see --accessType below).  For read-only access, users should perform the looback
     mount with the read-only flag (see mount(8)).  This mode of operation facilitates the creation of public, read-only filesys-
     tems.

   Simultaneous Mounts
     Althogh it functions over the network, the s3backer filesystem is not a distributed filesystem and does not support simultane-
     ous read/write mounts.  (This is not something you would normally do with a hard-disk partition either.)  s3backer does not
     detect this situation; it is up to the user to ensure that it doesn't happen.

   Logging
     In normal operation s3backer will log via syslog(3).  When run with the -d or -f flags, s3backer will log to standard error.

OPTIONS
     Options specific to s3backer are as follows:

     --accessFile=FILE
             Specify a file containing `accessID:accessKey' pairs, one per-line.  Blank lines and lines beginning with a `#' are
             ignored.  If no --accessKey is specified, this file will be searched for the entry matching the access ID specified
             via --accessId; if neither --accessKey nor --accessId is specified, the first entry in this file will be used.
             Default value is $HOME/.s3backer_passwd.

     --accessId=ID
             Specify Amazon S3 access ID.  Specify an empty string to force no access ID.  If no access ID is specified (and none
             is found in the access file) then s3backer will still function, but only reads of publicly available filesystems will
             work.

     --accessKey=KEY
             Specify Amazon S3 access key. To avoid publicizing this secret via the command line, use --accessFile instead of this
             flag.

     --accessType=TYPE
             Specify the Amazon S3 access privilege ACL type for newly written blocks.  The value must be one of `private', `pub-
             lic-read', `public-read-write', or `authenticated-read'.  Default is `private'.

     --baseURL=URL
             Specify the base URL. Default is `http://s3.amazonaws.com/'.

     --blockSize=SIZE
             Specify the block size. This must be a power of two and should be a multiple of the kernel's native page size.  The
             size may have an optional suffix 'K' for kilobytes, 'M' for megabytes, etc.  s3backer supports partial block opera-
             tions, though for writes this may require a read and then a write; proper alignment of the s3backer block size with
             the intended use (e.g., the block size of the `upper' filesystem) will minimize or eliminate the extra reads.
             s3backer will attempt to auto-detect the block size by reading block number zero.  If this option is not specified,
             the auto-detected value will be used.  If this option is specified but disagrees with the auto-detected value,
             s3backer will exit with an error unless --force is also given.  If auto-detection fails because block number zero does
             not exist, and this option is not specified, then the default value of 4K (4096) is used.

     --cacheSize=SIZE
             Specify the size of the MD5 checksum cache (in blocks).  If the cache is full when a new block is written, the write
             will block until there is room.  Therefore, it is important to configure --cacheTime and --cacheSize according to the
             frequency of writes to the filesystem overall and to the same block repeatedly.  Alternately, a value equal to the
             number of blocks in the filesystem eliminates this problem but consumes the most memory when full (each entry in the
             cache is approximately 40 bytes).  A value of zero disables the cache.  Default value is 1000.

     --cacheTime=MILLIS
             Specify in milliseconds the time after a block has been successfully written for which the MD5 checksum of the block's
             contents should be cached, for the purpose of detecting stale data during subsequent reads.  A value of zero means
             `infinite' and provides a guarantee against reading stale data; however, you should only do this when --cacheSize is
             configured to be equal to the number of blocks; otherwise deadlock will (eventually) occur.  This value must be at
             least as big as --minWriteDelay. This value must be set to zero when --cacheSize is set to zero (cache disabled).
             Default value is 10 seconds.

     --connectTimeout=SECONDS
             Specify a timeout in seconds for the initial HTTP connection.  Default is 30 seconds.

     --debug
             Enable logging of debug messages.  Note that this flag is different from -d, which is a flag to FUSE.  Both the -d and
             -f FUSE flags imply this flag.

     --filename=NAME
             Specify the name of the single file that appears in the s3backer filesystem.  Default is `file'.

     --force
             Proceed even if the value specified by --blockSize or --size disagrees with the auto-detected value.  This is will
             certainly lead to reading garbled data and should only be used when you intend to write over an existing filesystem
             with a new one.

     -h --help
             Print a help message and exit.

     --initialRetryPause=MILLIS
             Specify the initial pause time in milliseconds before the first retry attempt after failed HTTP operations.  Failures
             include network failures and timeouts, 5xx server errors, and reads of stale data (i.e., MD5 mismatch); s3backer will
             make multiple retry attempts using an exponential backoff algorithm, starting with this initial retry pause time.
             Default value is 200ms.  See also --maxRetryPause.

     --ioTimeout=SECONDS
             Specify a timeout in seconds for the completion of an HTTP operation after the initial connection.  Default is 30 sec-
             onds.

     --maxRetryPause=MILLIS
             Specify the total amount of time in milliseconds s3backer should pause when retrying failed HTTP operations before
             giving up.  Failures include network failures and timeouts, 5xx server errors, and reads of stale data (i.e., MD5 mis-
             match); s3backer will make multiple retry attempts using an exponential backoff algorithm, up to this maximum total
             retry pause time.  This value does not include the time it takes to perform the HTTP operations themselves.  Default
             value is 30000 (30 seconds).  See also --initialRetryPause.

     --minWriteDelay=MILLIS
             Specify a minimum time in milliseconds between the successful completion of a write and the initiation of another
             write to the same block. This delay ensures that S3 doesn't receive the writes out of order.  Default value is 500ms.

     --prefix=STRING
             Specify a prefix to prepend to the resource names within bucket that identify each block.  Default is the empty
             string.

     --size=SIZE
             Specify the size (in bytes) of the single file to be exported by the filesystem.  The size may have an optional suffix
             'K' for kilobytes, 'M' for megabytes, 'G' for gigabytes, or 'T' for terabytes.  s3backer will attempt to auto-detect
             the block size by reading block number zero.  If this option is not specified, the auto-detected value will be used.
             If this option is specified but disagrees with the auto-detected value, s3backer will exit with an error unless
             --force is also given.

     --version
             Output version and exit.

     In addition, s3backer accepts all of the generic FUSE options as well.  Here is a partial list:

     -d      Enable FUSE debug mode.  Implies -f and --debug.

     -f      Run in the foreground (do not fork).  Implies --debug.

     -s      Run in single-threaded mode.

     -o allow_root
             Allow root (only) to view backed file.

     -o allow_other
             Allow all users to view backed file.

     -o nonempty
             Allow all users to view backed file.

     -o uid=UID
             Override the user ID of the backed file, which defaults to the current user ID.

     -o gid=GID
             Override the group ID of the backed file, which defaults to the current group ID.

     -o sync_read
             Do synchronous reads.

     -o max_readahead=NUM
             Set maximum read-ahead (in bytes).

     In addition, s3backer passes the following flags which are optimized for s3backer to FUSE (unless overridden by the user on
     the command line):

     -o kernel_cache
     -o fsname=s3backer
     -o use_ino
     -o entry_timeout=31536000
     -o negative_timeout=31536000
     -o attr_timeout=31536000
     -o default_permissions
     -o nodev
     -o nosuid

FILES
     $HOME/.s3backer_passwd
             Contains Amazon S3 `accessID:accessKey' pairs.

SEE ALSO
     losetup(8), mount(8), umount(8), fusermount(8).

     s3backer: FUSE-based single file backing store via Amazon S3, http://s3backer.googlecode.com/.

     Amazon Simple Storage Service (Amazon S3), http://aws.amazon.com/s3.

     FUSE: Filesystem in Userspace, http://fuse.sourceforge.net/.

     Google Search for `linux page cache', http://www.google.com/search?q=linux+page+cache.

BUGS
     s3backer should really be implemented as a device rather than a filesystem.  However, this would require writing a kernel mod-
     ule instead of a simple user-space daemon, because Linux does not provide a user-space API for devices like it does for
     filesystems with FUSE.  Implementing s3backer as a filesystem and then using the loopback mount is a simple workaround.

AUTHOR
     Archie L. Cobbs <archie@dellroad.org>

BSD                                                        June 21, 2008                                                        BSD
}}}